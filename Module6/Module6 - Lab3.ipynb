{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT210x - Programming with Python for DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module6- Lab3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is intentionally missing! Read the directions on the course lab page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Load up the /Module6/Datasets/parkinsons.data data set into a variable X, being sure to drop the name column.\n",
    "\n",
    "X = pd.read_csv(\"Datasets/parkinsons.data\", sep=\",\")\n",
    "X.drop('name', axis = 1, inplace = True)\n",
    "#print(X.head(10))\n",
    "#print(X.dtypes)\n",
    "#print(X.info)\n",
    "#print(X.describe())\n",
    "#print(X.isnull().sum()) # No NaNs!\n",
    "#print(X.dtypes) # All object types are correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Splice out the status column into a variable y and delete it from X.\n",
    "\n",
    "y = X.status\n",
    "X.drop('status', axis = 1, inplace = True)\n",
    "#print(X.head(5))\n",
    "#print(y.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Perform a train/test split. 30% test group size, with a random_state equal to 7.\n",
    "#from sklearn.cross_validation import train_test_split #code at top\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a SVC classifier. Don't specify any parameters, just leave everything as default. Fit it against your training data and then score your testing data.\n",
    "\n",
    "#from sklearn.svm import SVC #code at top\n",
    "model = SVC() \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\n",
      " 0.813559322034\n"
     ]
    }
   ],
   "source": [
    "#Score the test data\n",
    "\n",
    "score = model.score\n",
    "print(\"Score:\\n\", score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest score obtained:0.915254237288\n",
      "C value:1.65\n",
      "gamma value:0.005\n"
     ]
    }
   ],
   "source": [
    "# Program a naive, best-parameter searcher by creating a nested for-loops. The outer for-loop should iterate a variable C\n",
    "# from 0.05 to 2, using 0.05 unit increments. The inner for-loop should increment a variable gamma from 0.001 to 0.1, using\n",
    "# 0.001 unit increments. As you know, Python ranges won't allow for float intervals, so you'll have to do some research on\n",
    "# NumPy ARanges, if you don't already know how to use them.\n",
    "\n",
    "# Since the goal is to find the parameters that result in the model having the best score, you'll need a best_score = 0 variable\n",
    "# that you initialize outside of the for-loops. Inside the for-loop, create a model and pass in the C and gamma parameters into\n",
    "# the class constructor. Train and score the model appropriately. If the current best_score is less than the model's score, then\n",
    "# update the best_score, being sure to print it out, along with the C and gamma values that resulted in it.        \n",
    "best_score = 0\n",
    "for i in np.arange(start = 0.05, stop = 2.05, step = 0.05):\n",
    "    for j in np.arange(start = 0.001, stop = 0.101, step = 0.001):\n",
    "        model = SVC(C = i, gamma = j)\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_C = model.C\n",
    "            best_gamma = model.gamma\n",
    "            \n",
    "print(\"The highest score obtained:\"+ str(best_score))\n",
    "print(\"C value:\"+ str(best_C)) \n",
    "print(\"gamma value:\" + str(best_gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest score obtained:0.932203389831\n",
      "C value:1.5\n",
      "gamma value:0.1\n"
     ]
    }
   ],
   "source": [
    "# Wait a second. Pull open the dataset's label file from: https://archive.ics.uci.edu/ml/datasets/Parkinsons\n",
    "# Look at the units on those columns: Hz, %, Abs, dB, etc. What happened to transforming your data? With all of those units\n",
    "# interacting with one another, some pre-processing is surely in order. Right after you splice out the status column, but before\n",
    "# you process the train/test split, inject SciKit-Learn pre-processing code. Unless you have a good idea which one is going to work\n",
    "# best, you're going to have to try the various pre-processors one at a time, checking to see if they improve your predictive accuracy.\n",
    "# Experiment with Normalizer(), MaxAbsScaler(), MinMaxScaler(), and StandardScaler().\n",
    "\n",
    "#from sklearn import preprocessing #code at top\n",
    "\n",
    "#T = preprocessing.StandardScaler().fit_transform(X) #The highest score obtained:0.932203389831\n",
    "#T = preprocessing.MinMaxScaler().fit_transform(X) #The highest score obtained:0.881355932203\n",
    "#T = preprocessing.Normalizer().fit_transform(X) #The highest score obtained:0.796610169492\n",
    "T = preprocessing.scale(X) #The highest score obtained:0.932203389831\n",
    "#T = X #The highest score obtained:0.915254237288\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(T, y, test_size = 0.3, random_state = 7)\n",
    "\n",
    "best_score = 0\n",
    "for i in np.arange(start = 0.05, stop = 2.05, step = 0.05):\n",
    "    for j in np.arange(start = 0.001, stop = 0.101, step = 0.001):\n",
    "        model = SVC(C = i, gamma = j)\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_C = model.C\n",
    "            best_gamma = model.gamma\n",
    "            \n",
    "print(\"The highest score obtained:\"+ str(best_score))\n",
    "print(\"C value:\"+ str(best_C)) \n",
    "print(\"gamma value:\" + str(best_gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest score obtained:0.966101694915\n",
      "C value:1.7\n",
      "gamma value:0.06\n",
      "isomap n_neighbors:2\n",
      "isomap n_components:4\n"
     ]
    }
   ],
   "source": [
    "# The accuracy score keeps creeping upwards. Let's have one more go at it. Remember how in a previous lab we discovered that SVM's\n",
    "# are a bit sensitive to outliers and that just throwing all of our unfiltered, dirty or noisy data at it, particularly in\n",
    "# high-dimensionality space, can actually cause the accuracy score to suffer?\n",
    "# Well, let's try to get rid of some useless features. Immediately after you do the pre-processing, run PCA on your dataset. The\n",
    "# original dataset has 22 columns and 1 label column. So try experimenting with PCA n_component values between 4 and 14. Are you able\n",
    "# to get a better accuracy?\n",
    "\n",
    "#No, the accuracy levels off at the same value as before from 7 components onwards.\n",
    "\n",
    "# If you are not, then forget about PCA entirely, unless you want to visualize your data. However if you are able to get a higher score,\n",
    "# then be *sure* keep that figure in mind, and comment out all the PCA code.\n",
    "# In the same spot, run Isomap on the data, before sending it to the train / test split. Manually experiment with every inclusive\n",
    "# combination of n_neighbors between 2 and 5, and n_components between 4 and 6. Are you able to get a better accuracy?\n",
    "\n",
    "#from sklearn.manifold import Isomap #code at top\n",
    "\n",
    "# You're going to have to write nested for loops that wrap around everything from here on down!\n",
    "best_score = 0\n",
    "for k in range(2, 6):\n",
    "    for l in range(4, 7):\n",
    "        #from sklearn.decomposition import PCA #code at top\n",
    "        #pca = PCA(n_components = 14)\n",
    "        #X_pca = pca.fit_transform(T)\n",
    "        \n",
    "        #from sklearn.manifold import Isomap\n",
    "        iso = Isomap(n_neighbors = k, n_components = l)\n",
    "        X_iso = iso.fit_transform(T)\n",
    "\n",
    "        # Perform a train/test split. 30% test group size, with a random_state equal to 7.\n",
    "        #from sklearn.cross_validation import train_test_split #code at top\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_iso, y, test_size = 0.3, random_state = 7)\n",
    "\n",
    "        from sklearn.svm import SVC\n",
    "               \n",
    "        for i in np.arange(start = 0.05, stop = 2.05, step = 0.05):\n",
    "            for j in np.arange(start = 0.001, stop = 0.101, step = 0.001):\n",
    "                model = SVC(C = i, gamma = j)\n",
    "                model.fit(X_train, y_train)\n",
    "                score = model.score(X_test, y_test)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_C = model.C\n",
    "                    best_gamma = model.gamma\n",
    "                    best_n_neighbors = iso.n_neighbors\n",
    "                    best_n_components = iso.n_components\n",
    "print(\"The highest score obtained:\"+ str(best_score))\n",
    "print(\"C value:\"+ str(best_C)) \n",
    "print(\"gamma value:\" + str(best_gamma))\n",
    "print(\"isomap n_neighbors:\" + str(best_n_neighbors))\n",
    "print(\"isomap n_components:\"+ str(best_n_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
